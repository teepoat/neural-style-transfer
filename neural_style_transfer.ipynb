{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install urllib3"
      ],
      "metadata": {
        "id": "mdeNciK-uXcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# origs\n",
        "CAR_IMAGE_LINK = \"https://proproprogs.ru/htm/nn_pytorch/files/pytorch-svertochnye-neyronnye-seti-vgg-16-i-vgg-19.files/image003.jpg\"\n",
        "PATRICK_BATEMAN_LINK = \"https://avatars.mds.yandex.net/i?id=65a7105a5e792e453a3297ed7efa063f_l-12384085-images-thumbs&n=13\"\n",
        "#styles\n",
        "PAINTING1_IMAGE_LINK = \"https://i.pinimg.com/736x/f4/fe/95/f4fe9569c69037636b41ada357efe559.jpg\"\n",
        "PAINTING2_IMAGE_LINK = \"https://avatars.mds.yandex.net/i?id=561355cb5cb6fed9acdcc60ccc12358c_l-5505574-images-thumbs&n=13\"\n",
        "PAINTING3_IMAGE_LINK = \"https://raw.githubusercontent.com/kirill-ionkin/NST_Gatys/refs/heads/main/example/style_1.jpg\"\n",
        "GRAFFITI1_IMAGE_LINK = \"https://yandex-images.clstorage.net/qtS9G7366/c733613yWfJ/HO0gQjXc1ZbGC1QvWLbP1GxS7oziTDPCbb0JJFoAeLU_MBlsevzXrFnczv8eyTDeJYTZ4E0hMGRQTtt_YInymUq99RPl3BSUgpkTK8hyzJc8kesYchkwVONllOyTzvMtILkTculplTsYW0k7zoepDzbVxGwYaOA4hJBWMiEYrorX4azFvY4TEgKdlmIas8QXMhApinHMoAHiK9EtkMt84mv7nf9vrJb431TXsoEG71p6Hc7iG6Kp887fETgkVO_AVSkrivSF3VwDWldlEbUInn1T6oi0CuEAbq6fZhMDsicuNN-woyOcOlVdGvMIRiVTttMMKRDo6LwNGpDw4NOqyp2uIMP7ixLTTJlSo5k6xRr1mqMH-sPhRqDjkahajTzsYLRV8-pilTDS1Za2y41nEjqaTONabGG8hhQaPaWW6sacKuPHtA7aWcEbkuoatorb8ZHlSHuCqYRhZ1TgUAlyb-s2UHDpJRu-15keMwcIp9m6XMuglepi-InS2XcgFy6NFajizHoPlVqH0RQhGrUMHDXb4Uz8Qu5DLSdfKNPKsuWuutpwK2eauNnTETkOzuXRdliD4petrrMH0x07Llhvx1ckaIo7z9dSypRbJ9u8RF97mSwBsA8pTOhrVGAfwXas4nnbtKGtE3aTU1a_AwblGzXZROaXqqj1TFoZ-yCe5YUYraNMsUuf34eV2aFX9MwfNlcniHhHIoaqo9FsXUwxLCdzU3MpbF-w3Z5TfAZFJB3xHE3lV2rhu4cQET5snqvHHyjsRzzBE99Hk5EiFrtC2PPcZUm_zOjNYSDd4pDFuyBre5C_4ajTNlsb2fwAwaTbsh0MbBpn6HeJ2dq_ZhpjCd5sIEV7glVUwhMS6Vh8z5KzEeVNsshhSKzsVuGbDzpgLrWfeaqln3KR3FO-AwFoVD3Xzu6aLaZ0zFOYsGkeZAzS4aJENMlQkoAWW6ITtsTbe5GjyHhOoQjgqZ4sUA\"\n",
        "GRAFFITI2_IMAGE_LINK = \"https://avatars.mds.yandex.net/i?id=a9c7baaf914d26034afa9808f0729dc9_l-5365143-images-thumbs&n=13\""
      ],
      "metadata": {
        "id": "zTr5f-Ctyw-b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "def image_by_link(url: str):\n",
        "  return Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "img_orig = image_by_link(PATRICK_BATEMAN_LINK).convert(\"RGB\")\n",
        "img_style = image_by_link(PAINTING3_IMAGE_LINK).convert(\"RGB\")"
      ],
      "metadata": {
        "id": "FnVwOu7OBgiH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(img_orig)\n",
        "display(img_style)"
      ],
      "metadata": {
        "id": "GXbIlfWHvY6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "SCIrkb00ekS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "class StyleModel(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self._model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
        "    self.transforms = models.VGG19_Weights.IMAGENET1K_V1.transforms()\n",
        "    self.requires_grad_(False)\n",
        "    self._model.features.requires_grad_(False)\n",
        "    self._model.features.eval()\n",
        "    self.layers = self._model.features\n",
        "    self.idx = (0, 5, 10, 19, 28, 34)\n",
        "\n",
        "  def forward(self, x):\n",
        "    outputs = []\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      x = layer(x)\n",
        "      if i in self.idx:\n",
        "        outputs.append(x.squeeze())\n",
        "\n",
        "    return outputs[:-1], outputs[-1]"
      ],
      "metadata": {
        "id": "w5qxgmJQwcOD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torchvision.transforms.v2 as tfs_v2\n",
        "from tqdm import tqdm\n",
        "\n",
        "def loss_content_eval(orig, x):\n",
        "  return ((orig - x).square()).mean()\n",
        "\n",
        "def gram_matrix(x):\n",
        "  gram = []\n",
        "  for i in range(len(x)):\n",
        "    a = x[i].squeeze().view(x[i].shape[0], -1)\n",
        "    gram.append(a.mm(a.mT) / a.shape[1])\n",
        "  return  gram\n",
        "\n",
        "def loss_style_eval(gram_style, gram, weights=[1., 0.8, 0.5, 0.3, 0.1]):\n",
        "  loss = 0\n",
        "  for i in range(len(gram_style)):\n",
        "    loss += ((gram_style[i] - gram[i]) ** 2).mean() * weights[i]\n",
        "  return loss\n",
        "\n",
        "def normalize(x):\n",
        "  return (x - x.min()) / (x.max() - x.min())\n",
        "\n",
        "# create model\n",
        "model = StyleModel().to(device)\n",
        "model.eval()\n",
        "\n",
        "# transform images\n",
        "transforms = tfs_v2.Compose([\n",
        "  tfs_v2.ToImage(),\n",
        "  tfs_v2.ToDtype(torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "img_orig = transforms(img_orig).to(device)\n",
        "img_style = transforms(img_style).to(device)"
      ],
      "metadata": {
        "id": "sDC2YOTJ2Xtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create image we're stylizing\n",
        "img = img_orig.clone()\n",
        "img.requires_grad_(True)\n",
        "\n",
        "# evaluate content and style tensors\n",
        "style_orig, content_orig = model(img)\n",
        "style_style, _ = model(img_style)\n",
        "\n",
        "gram_style = gram_matrix(style_style)\n",
        "\n",
        "# detach constants\n",
        "content_orig = content_orig.detach()\n",
        "gram_style = [i.detach() for i in gram_style]\n",
        "\n",
        "# hyperparameters\n",
        "epochs = 2000\n",
        "opt = optim.Adam(params=[img], lr=0.01)\n",
        "content_coeff = 1\n",
        "style_coeff = 1e6\n",
        "\n",
        "# training loop\n",
        "progress_bar = tqdm(range(epochs), desc=\"Style Transfer Progress\")\n",
        "for _ in progress_bar:\n",
        "  style, content = model(img)\n",
        "  gram = gram_matrix(style)\n",
        "\n",
        "  loss_content = loss_content_eval(content, content_orig)\n",
        "  loss_style = loss_style_eval(gram_style, gram)\n",
        "  loss = content_coeff * loss_content + style_coeff * loss_style\n",
        "  progress_bar.set_postfix(loss_content=loss_content.item(), loss_style=loss_style.item(), loss=loss.item())\n",
        "\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "\n",
        "  img.data.clamp_(0, 1)"
      ],
      "metadata": {
        "id": "CL3o3WzUgvXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = img.requires_grad_(False)\n",
        "x = x.clamp(0, 1) * 255.0\n",
        "x = x.permute(1, 2, 0)\n",
        "x = x.cpu().numpy()\n",
        "x = x.astype('uint8')\n",
        "Image.fromarray(x, \"RGB\")"
      ],
      "metadata": {
        "id": "3TLFv4zFd0Im"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}